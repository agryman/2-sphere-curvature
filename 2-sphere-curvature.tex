\documentclass[11pt, oneside]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{geometry}
\geometry{letterpaper}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{commath}

\usepackage[autostyle]{csquotes}

\usepackage{hyperref}

\usepackage[
backend=biber,
style=alphabetic,
sorting=ynt
]{biblatex}
\addbibresource{shared/references.bib}

% put fuzz last because it redefines \t
\usepackage{fuzz}

\input{newcommands}

\newtheorem{theorem}{Theorem}
\newtheorem*{remark}{Remark}

\title{Proof that $\Stwo$ is curved}
\author{Arthur Ryman, {\tt arthur.ryman@gmail.com}}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Leonard Susskind,  in Lecture 3 of his Stanford University course on General Relativity,
asks his class to prove, as an exercise, that $\Stwo$ is curved.
This article attempts to do so.
The approach taken here is to precisely formalize every concept involved in the proof.
\end{abstract}

\section{Introduction}

The 2-sphere, $\Stwo$, is an extremely ubiquitous and illuminating example of a Riemannian manifold.
It appears in many interesting contexts including complex analysis, special relativity, electromagnetism, and quantum mechanics.
It is a compact submanifold of $\Rthree$ and so can be clearly visualized, unlike its higher-dimensional versions.
These attributes make $\Stwo$ an ideal concrete example for illustrating the concepts of 
abstract Riemannian geometry.

In Lecture 3 of his Stanford University course on General Relativity \cite{susskind-gr3},
Leonard Susskind challenges his class to prove that $\Stwo$ is curved.
He does this before defining curvature.
The class is simply challenged to show that there is no coordinate system in which the components
of the metric tensor become those of flat space.
The goal of this article is to prove that $\Stwo$ is curved.

I can imagine two possible coordinate-based routes to the proof, 
namely either showing that no suitable coordinate system exists, 
or that some tensorial quantity related to curvature doesn't vanish.

\subsection{A Topological Approach}

Before proceeding with the coordinate approach, it is illuminating to discuss a purely topological one.
If $\Stwo$ is flat then its tangent bundle is trivial and so has a non-zero cross section.
But a cross section of the tangent bundle is a vector field on $\Stwo$.
A vector field on $\Stwo$ defines a diffeomorphism of $\Stwo$ that is homotopic to the identity map.
If the vector field never vanishes then this diffeomorphism has no fixed points.
The Lefschetz fixed-point theorem tells us that any space $M$ that has such a diffeomorphism must have a vanishing Euler characteristic
$\chi(M) = 0$. But $\chi(\Stwo) = 2$. Therefore $\Stwo$ cannot be flat.

While this proof answers the question, it doesn't provide much insight into curvature in general.
For example, the 3-sphere $\Sthree$ must surely also be curved, but $\chi(\Sthree) = 0$.
Curvature is a local, geometric property, not a global, topological one.
A coordinate proof for $\Stwo$ should generalize to all higher-dimensional spheres and to other submanifolds of $\R^n$.

\subsection{The Coordinate System Approach}
 
The most direct route is to attempt to construct a coordinate system that makes the metric flat.
This approach will lead to differential equations that the coordinate functions must satisfy.
I suspect that one can show that the differential equations have no solution, probably due to the failure of some
integrability condition.

For example, suppose one is given two functions $f(x,y)$ and $g(x,y)$, and one is asked to find $F(x,y)$ such that
\begin{align}
	\frac{\partial F}{\partial x}	&= f \\
	\frac{\partial F}{\partial y}	&= g
\end{align}
If $F$ exists then $f$ and $g$ must satisfy the following integrability condition
\begin{equation}
\begin{split}
	\frac{\partial f}{\partial y} 	& = \frac{\partial}{\partial y} \left( \frac{\partial F}{\partial x} \right) \\
						& = \frac{\partial^2 F}{\partial y \partial x} \\
						& = \frac{\partial^2 F}{\partial x \partial y} \\
						& = \frac{\partial}{\partial x} \left( \frac{\partial F}{\partial y} \right) \\
						& = \frac{\partial g}{\partial x}
	\end{split}
\end{equation}

\subsection{The Curvature Tensor Approach}

The idea here is to define a tensor that vanishes on flat space but not on $\Stwo$.
The existence of such a tensor proves that $\Stwo$ is not flat.
Of course, the tensor in question is the Riemann curvature tensor but Susskind has not introduced it yet.

Geometrically, the curvature tensor arises when one considers the parallel transport of a tangent vector around a
small closed loop anchored at some point.
How hard would it be to define this tensor from first principles?
Let $M$ be a smooth manifold, let $p \in M$ be some point, and let $M_p$ denote the tangent space at $p$.
Let $V \in M_p$ be a tangent vector.
Let $X, Y$ be tangent vectors at $p$.
Consider the small path anchored at $p$ defined by moving along $X$, then $Y$, then $-X$, and then finally $-Y$.
Transport $V$ along this closed path.
The result is a new vector $W$ which is a linear transform of $V$ that depends linearly on $X$ and $Y$.
\begin{equation}
	W = R_p(X,Y)V
\end{equation}

One suspects that the amount of change of $V$ is proportional to the two-dimensional area spanned by $X$ and $Y$, hence $R$ depends
on the area element $X \wedge Y$, or 
\begin{equation}
	R_p(X,Y) = -R_p(Y,X)
\end{equation}

The tricky bit here is to define parallel transport.
It probably boils down to geodesic movement.

Parallel transport has an intuitive, physical meaning.
Suppose we have a massive, rigid body at rest at the point $p$.
By this I mean that the centre of mass of the body coincides with $p$.
Such a body defines a frame of reference at $p$.
We take $p$ to be the origin and pick several reference points on the body such that their displacements from $p$ define a set of basis vectors.
We give the body a slight push in some direction $V$, being careful not induce any rotation.
We achieve this by apply the same force in the direction $V$ at several points on the body, balancing them about the body's centre of mass.
We then let the body move a small distance in the direction defined by $V$ to some new point $p'$.
The new positions of the reference points define a new set of basis vectors.
For small movements the new basis vector will be defined by a linear transformation of the old basis vectors.

We can determine the equations of motion by defining a Hamiltonian.
It is natural to use the metric tensor as defining the kinetic energy of the system.
Solving the Hamiltonian equations of motion should yield a geodesic through $p$ in the direction of $V$ and the linear transformation of
the frame of reference.

Dirac, in his book on General Relativity, defined parallel transport for submanifolds of  $\R^n$ as the projections onto the submanifold of
straight line motion in $\R^n$.

\section{Manifolds}

Manifolds can be defined in several ways.
The way I prefer to think about them is that, first of all, they are  based on topological spaces.
A manifold is therefore a topological space with some additional structure.
This additional structure allows one to regard a manifold as, locally, being like an open subset of $\R^n$
for some natural number $n$ referred to as the dimensional of the manifold.
In the following, let $M$ be a topological space of dimension $n$.

\subsection{Charts}
A chart $\phi$ on $M$ is a continuous injection of some open subset $U \subseteq M$ into $\R^n$.
A chart gives every point $p \in U$ in its domain of definition a tuple of $n$ real number coordinates.
\begin{equation}
	\phi: U \inj \R^n
\end{equation}

\subsection{Transition Functions}
Let $U, V, W$ be open subsets of $M$ with $W = U \cap V$.
Let $\phi: U \inj \R^n$ and $\psi: V \inj \R^n$ be charts.
Every point $p \in W$ is therefore given two, typically distinct, tuples of coordinates.
The mapping from one coordinate tuple to the other is called the transition function defined by the pair of charts.
Let $t_{\phi,\psi}$ denote that transition function that maps the $\phi$ coordinates to the $\psi$ coordinates.
\begin{equation}
	\forall x \in \phi(W) @ t_{\phi,\psi}(x) = \psi(\phi^{-1}(x))
\end{equation}

\subsection{Compatible Charts}
Let $\mathcal{F}$ be some family of partial injections from $\R^n$ to $\R^n$, e.g. continuous, differentiable, smooth, defined on the open subsets.
\begin{equation}
	\mathcal{F} \subseteq \R^n \pinj \R^n
\end{equation}

A pair of charts are said to be compatible with respect to $\mathcal{F}$ when their transition functions belong to $\mathcal{F}$.

\subsection{Atlases}
A set of pairwise compatible charts that cover $M$ is called an atlas for $M$.
An atlas gives $M$ a manifold structure.
If the charts are only required to be continuous then $M$ is called a topological manifold.
If the charts are required to be differentiable then the atlas is called a differential or differentiable structure and $M$ is called
a differentiable manifold.
Infinitely differentiable charts are called smooth charts.
We are only concerned with smooth charts and manifolds.

In general, we normally consider an atlas to be a maximal set of charts.
A given set of mutually compatible charts belongs to a unique maximal atlas.
The given set is said to generate the maximal atlas.

\subsection{Smooth Mappings}
Mappings from one smooth manifold to another are called smooth when they are smooth when expressed in their coordinate charts.
A smooth mapping that has a smooth inverse is called a diffeomorphism.

\subsection{Tangent Vectors}
A tangent vector $X$ at the point $p \in M$ is a mapping from the set of smooth functions at $p$ to $\R$ that satisfies the following 
for all $c \in \R$ and $f,g \in C^{\infty}(M,p)$
\begin{align}
	X(cf) &= cX(f) \\
	X(f + g) &= X(f) + X(g) \\
	X(fg) &= g(p)X(f) + f(p)X(g)
\end{align}

A smooth curve $\gamma: \R \fun M$ defines a tangent vector $X$ at $p=\gamma(0)$ by
\begin{equation}
	X(f) = \left.\frac{df(\gamma(t))}{dt}\right|_{t=0}
\end{equation}

\subsection{Tangent Bundles}

The set of all tangent vectors at $p$ is denoted $M_p$ or $T_p(M)$. 
It is an $n$-dimensional vector space and is called the tangent space at $p$.
The set of all tangent spaces is called the tangent bundle and is denoted $T(M)$
\begin{equation}
	T(M) = \{~ (p,X) | p \in M, X \in M_p ~\}
\end{equation}

The tangent bundle $T(M)$ is a smooth vector bundle over $M$ under the natural projection
$\pi: T(M) \fun M, \pi(p,X) = p$.

\section{Real Analysis}

The set $\Stwo$ is a real submanifold of $\Rthree$, so first I need to formalize the real numbers.

\subsection{The Real Numbers}

Let $\R$ denote the given set of real numbers.
\begin{zed}
	[\R]
\end{zed}

Let $\zeroR$ and $\oneR$ denote the zero and unit elements of the real numbers.
\begin{axdef}
	\zeroR: \R \\
	\oneR: \R
\end{axdef}

Define $\Rnz$ to be the set of non-zero real numbers, 
also referred to as the punctured real number line.
\begin{zed}
	\Rnz == \R \setminus \{ \zeroR \}
\end{zed}

The usual comparison relations have the following signatures.
\begin{axdef}
	\_ \ltR \_: \R \rel \R \\
	\_ \leR \_: \R \rel \R \\
	\_ \gtR \_: \R \rel \R \\
	\_ \geR \_: \R \rel \R
\end{axdef}

Define $\Rpos$ to be the set of positive real numbers.
\begin{zed}
	\Rpos == \{~ x: \R | x \gtR \zeroR ~\}
\end{zed}

The usual negative operator has the following signature.
\begin{axdef}
	\negR: \R \fun \R
\end{axdef}

Define $\absR{x}$ to be $\abs{x}$, the absolute value of the real number $x$.
\begin{axdef}
	\absR: \R \fun \R
\where
	\forall x: \R @ \absR(x) = \IF x \geR \zeroR \THEN x \ELSE \negR~x
\end{axdef}

The usual arithmetic operators have the following signatures.
\begin{axdef}
	\_ \addR \_: \R \cross \R \fun \R \\
	\_ \subR \_: \R \cross \R \fun \R \\
	\_ \mulR \_: \R \cross \R \fun \R \\
	\_ \divR \_: \R \cross \Rnz \fun \R
\end{axdef}

Define $\sqrtR{x}$ to be $\sqrt{x}$, the non-negative square root of the non-negative real number $x$.
\begin{axdef}
	\sqrtR: \R \pfun \R
\where
	\sqrtR = \{~ x: \R | x \geR \zeroR @ x \mulR x \mapsto x ~\}
\end{axdef}

\subsection{Open Intervals}

Let $a$ and $b$ be real numbers.
The open interval bounded by $a$ and $b$ is the set of all real numbers between $a$ and $b$.
Define $\intervalRR(a,b)$ to be $(a,b)$, the open interval bounded by $a$ and $b$. 

\begin{axdef}
	\intervalRR: \R \cross \R \fun \power \R
\where
	\forall a, b: \R @ \\
	\t1	\intervalRR(a,b) = \{~ x: \R | a \ltR x \ltR b ~\}
\end{axdef}
Clearly, $\intervalRR(a,b)$ is empty if $a \geR b$.

\subsection{Open Balls}
Let $x$ be a real number and let $r$ be a strictly positive real number.
Define $\ballRR(x,r)$ to the the open interval that contains all points within distance $r$ of $x$.
\begin{axdef}
	\ballRR: \R \cross \Rpos \fun \power \R
\where
	\forall x: \R; r: \Rpos @ \\
	\t1	\ballRR(x,r) = \{~ x': \R | \absR(x' \subR x) \ltR r ~\}
\end{axdef}
\begin{remark}
$\ballRR(x,r) = \intervalRR(x-r, x+r)$
\end{remark}

\subsection{Neighbourhoods}

Let $x$ be a real number.
Any open ball centred at $x$ is called a neighbourhood of it.
Define $\neighR(x)$ to be the set of all neighbourhoods of $x$.

\begin{axdef}
	\neighR: \R \fun \power (\power \R)
\where
	\forall x: \R @ \\
	\t1	\neighR(x) = \{~ r: \Rpos @ \ballRR(x,r) ~\}
\end{axdef}
Clearly, every real number has an infinity of neighbourhoods.

\subsection{Functions}

Our next goal is to define continuity, limits, and differentiability.
These are {\it local} properties of functions
in the sense that they only depend on the values that the function takes in an arbitrarily small neighbourhood of a given point.
We therefore restrict our attention to functions that are defined in some neighbourhood of each point in their domains.
Let $x$ be a real number. 
Define $\FunR(x)$ to be the set of all real-valued functions that are defined in some neighbourhood of $x$.
\begin{axdef}
	\FunR: \R \fun \power(\R \pfun \R)
\where
	\forall x: \R @ \\
	\t1	\FunR(x) = \{~ f: \R \pfun \R | \exists U: \neighR(x) @ U \subseteq \dom f ~\}
\end{axdef}

Let $U$ be a subset of $\R$.
Define $\FunPR(U)$ to be the set of a real-valued functions on $U$ that are defined in some neighbourhood of every point of $U$.
\begin{axdef}
	\FunPR: \power \R \fun \power (\R \pfun \R)
\where
	\forall U: \power \R @ \\
	\t1	\FunPR(U) = \{~ f: U \fun \R | \forall x: U @ f \in \FunR(x) ~\}
\end{axdef}

\subsection{Continuity}

Let $f$ be a real-valued function and 
let $x$ be a real number.
The function $f$ is said to be continuous at $x$ if 
the domain of $f$ contains some neighbourhood $U$ of $x$ such that
for any $\epsilon > 0$ there is some $\delta > 0$ for which 
$f(x')$ is always within $\epsilon$ of $f(x)$
when $x' \in U$ is within $\delta$ of $x$.
\begin{argue}
\forall \epsilon > 0 @ \exists \delta > 0 @ \forall x' \in U @ \\
\t1	\abs{x' - x} < \delta \implies \abs{f(x') - f(x)} < \epsilon
\end{argue}

\begin{schema}{Continuous}
	f: \R \pfun \R \\
	x: \R
\where
	f \in \FunR(x)
\also
	\forall \epsilon: \Rpos @ \exists \delta: \Rpos@ \forall x': \dom f @ \\
	\t1	\absR(x' \subR x) \ltR \delta \implies \absR(f(x') \subR f(x)) \ltR \epsilon
\end{schema}

Define $\CzeroR(x)$ to be the set of all functions that are continuous at $x$.
\begin{axdef}
	\CzeroR: \R \fun \power(\R \pfun \R)
\where
	\forall x: \R @ \\
	\t1	\CzeroR(x) = \{~ f: \R \pfun \R | Continuous ~\}
\end{axdef}

Let $U$ be any subset of $\R$. 
Define $\CzeroPR(U)$ to be the set of all functions on $U$ that are continuous at each point in $U$.
\begin{axdef}
	\CzeroPR: \power \R \fun \power (\R \pfun \R)
\where
	\forall U: \power \R @ \\
	\t1	\CzeroPR(U) = \{~ f: \FunPR(U) | \forall x: U @ f \in   \CzeroR(x) ~\}
\end{axdef}

\begin{remark}
If $f \in \CzeroPR(U)$ then $U$ is a, possibly infinite, union of neighbourhoods.
\end{remark}

\subsection{Limits}

Let $x$ and $l$ be real numbers and
let $f$ be a real-valued function that is defined everywhere in some
neighbourhood $U$ of $x$, except possibly at $x$.
The function $f$ is said to approach the limit $l$ at $x$ if $f \oplus \{ x \mapsto l \}$ is continuous at $x$.
$$
	\lim_{x' \to x}{f(x')} = l
$$

\begin{schema}{Limit}
	f: \R \pfun \R \\
	x, l: \R
\where
	f \oplus \{x \mapsto l\} \in \CzeroR(x)
\end{schema}

Let $\limRR(x,l)$ be the set of all functions that approach the limit $l$ at $x$.
\begin{axdef}
	\limRR: \R \cross \R \fun \power(\R \pfun \R)
\where
	\forall x, l: \R @ \\
	\t1	\limRR(x,l) = \{~ f: \R \pfun \R | Limit ~\}
\end{axdef}

\begin{theorem}
If a function $f$ approaches some limit at $x$ then that limit is unique.
\begin{zed}
	\forall x, l, l': \R @ \\
	\t1	\forall f : \limRR(x,l) \cap \limRR(x,l') @ \\
	\t2		l = l'
\end{zed}
\end{theorem}

\begin{proof}
Suppose we are given real numbers
\begin{argue}
	x, l, l' \in \R 
\end{argue}
and a function
\begin{argue}
	f \in \limRR(x,l) \cap \limRR(x,l')
\end{argue}
Let $\epsilon$ be any positive real number
\begin{argue}
	\epsilon > 0
\end{argue}
Since $f$ approaches limits $l$ and $l'$ at $x$ there exists a real number $\delta > 0$ such that
\begin{argue}
	\forall x' \in \R |  \\
	\t1	\zeroR \ltR \abs{x' \subR x}< \delta @ \\
	\t2		 \abs{f(x') - l} < \epsilon \land \abs{f(x') - l'} < \epsilon
\end{argue}
For any such real number $x'$ we have
\begin{argue}
	\abs{l' - l} \\
	\t1	= \abs{(f(x') - l) - (f(x') - l')} 		& add and subtract $f(x')$ \\
	\t1	\leq \abs{f(x') - l} + \abs{f(x') - l'} 	& triangle inequality \\
	\t1	= 2\epsilon					& definition of limits
\end{argue}
Since the above holds for any $\epsilon > 0$ we must have
\begin{argue}
	l = l'
\end{argue}

\end{proof}

If $f$ approaches the limit $l$ at $x$ then define $\limFR(f,x) = l$.
By the preceding theorem, $\limFR(f,x)$ is well-defined when it exists.
\begin{axdef}
	\limFR: (\R \pfun \R) \cross \R \pfun \R
\where
	\limFR = \{~ Limit @ (f, x) \mapsto l ~\}
\end{axdef}

\subsection{Differentiability}

Let $f$ be a real-valued function on the real numbers, let $x$ be a real number,
and let $f$ be defined on some neighbourhood $U$ of $x$.

The function $f$ is said to be differentiable at $x$ if the following limit holds for some number $f'(x)$.
$$
\lim_{h \to 0} \frac{f(x+h) - f(x)}{h} = f'(x)
$$

\begin{remark}
If $f$ is differentiable at $x$ then $f$ is continuous at $x$.
\end{remark}

The geometric intuition behind the concept of differentiability is that $f$ is differentiable at $x$
when, very near $x$, the function $f$ is approximately a straight line with slope $f'(x)$.
$$
f(x + h) \approx f(x) + f'(x) h \quad \text{when} \quad \abs{h} \approx 0
$$
The slope $f'(x)$ is called the derivative of $f$ at $x$.

We can read this definition as saying that the approximate slope function $m(h)$ defined for 
small enough, non-zero values of $h$ by
$$
	m(h) = \frac{f(x + h) - f(x)}{h}
$$
approaches the limit $l = f'(x)$ as $h \to 0$.
$$
	\lim_{h\to 0}{m(h)} = l = f'(x)
$$

\begin{schema}{Differentiable}
	f: \R \pfun \R \\
	x, l: \R
\where
	f \in \CzeroR(x)
\also
	\LET m == (\lambda h: \Rnz | x \addR h \in \dom f @ (f(x \addR h) \subR f(x)) \divR h) @ \\
	\t1	\limFR(m, \zeroR) = l
\end{schema}
\begin{remark}
If $f$ is differentiable at $x$ then $L$ is unique.
\end{remark}

Define $\diffRR(x,L)$ to be the set of all functions $f$ that are differentiable at $x$ with $l = f'(x)$.
\begin{axdef}
	\diffRR: \R \cross \R \fun \power(\R \pfun \R)
\where
	\forall x, l: \R @ \\
	\t1	\diffRR(x, l) = \{~ f: \R \pfun \R | Differentiable ~\}
\end{axdef}

Define $\diffR(x)$ to be the set of all functions that are differentiable at $x$.
\begin{axdef}
	\diffR: \R \fun \power(\R \pfun \R)
\where
	\forall x: \R @ \\
	\t1	\diffR(x) = \bigcup \{~ l: \R @ \diffRR(x,l) ~\}
\end{axdef}

Let $U$ be any subset of $\R$. 
Define $\diffPR(U)$ to be the set of all functions on $U$
that are differentiable at each point of $U$.
\begin{axdef}
	\diffPR: \power \R \fun \power(\R \pfun \R)
\where
	\forall U: \power \R @ \\
	\t1	\diffPR(U) = \{~ f: \CzeroPR(U) | \forall x: U @ f \in \diffR(x) ~\}
\end{axdef}

\subsection{Derivatives}

The function $f'$ is called the derived function or the derivative of $f$.
Define $\derivFR(f,x)$ to be $f'(x)$.
\begin{axdef}
	\derivFR: (\R \pfun \R) \cross \R \pfun \R
\where
	\derivFR = \{~ Differentiable @ (f,x) \mapsto l ~\}
\end{axdef}

Define $\derivF(f)$ to be the derived function $f'$.
\begin{axdef}
	\derivF: (\R \pfun \R) \fun (\R \pfun \R)
\where
	\forall f: \R \pfun \R @ \\
		\t1	\derivF f = (\lambda x: \R | f \in \diffR(x) @ \derivFR(f,x)) 
\end{axdef}

\begin{remark}
If $f$ is differentiable on $U$ then $f'$ is not necessarily continuous on $U$.
Counterexamples exist.
If $f$ is uniformly differentiable then $f'$ is continuous, but I won't discuss uniform differentiability further.
\end{remark}

\subsection{Higher Order Derivatives}

Let $n$ be a natural number and let $x$ be a real number.
In differential geometry we normally deal with $C^n(x)$, the set of functions
that possess continuous derivatives of order $0, \ldots, n$ at $x$.
Define $\CnR(n,x)$ to be the set of all functions that have continuous derivatives of order $0, \ldots, n$ at $x$.
\begin{axdef}
	\CnR: \nat \cross \R \fun \power(\R \pfun \R)
\where
	\forall x: \R @ \\
	\t1	\CnR(0,x) = \CzeroR(x)
\also
	\forall n: \nat; x: \R @ \\
	\t1	\CnR(n + 1, x) = \{~ f: \CzeroR(x) | \derivF f \in \CnR(n,x) ~\}
\end{axdef}

Let $n$ be a natural number and let $U$ be a subset of $\R$.
Define $\CnPR(n,U)$ to be the set of all functions on $U$ that have continuous derivatives of order $0, \ldots, n$
at every point of $U$.
\begin{axdef}
	\CnPR: \nat \cross \power \R \fun \power(\R \pfun \R)
\where
	\forall n: \nat; U: \power \R @ \\
	\t1	\CnPR(n,U) = \{~ f: \FunPR(U) | \forall x: U @ f \in \CnR(n,x) ~\}
\end{axdef}

\subsection{Smoothness}

A function is said to be smooth if it possesses continuous derivatives of all orders.
Let $x$ be a real number.
Define $\smoothR(x)$ to be the set of all functions that are smooth at $x$.
\begin{axdef}
	\smoothR: \R \fun \power(\R \pfun \R)
\where
	\forall x: \R @ \\
	\t1	\smoothR(x) = \{~ f: \FunR(x) | \forall n: \nat @ f \in \CnR(n, x) ~\}
\end{axdef}

Define $\smoothPR(U)$ to be the set of all functions on $U$ that are smooth at every point of $U$.
\begin{axdef}
	\smoothPR: \power \R \fun \power (\R \pfun \R)
\where
	\forall U: \power \R @ \\
	\t1	\smoothPR(U) = \{~ f: \FunPR(U) | \forall x: U @ f \in \smoothR(x) ~\}
\end{axdef}

\section{Real Vector Spaces}

Since $\Stwo$ is a submanifold of $\R^3$, I need to start by defining $\R^3$ and the usual concepts 
associated with real vector spaces.

\subsection{Real $n$-tuples}

Let $n$ be a natural number.
A finite sequence of $n$ real numbers is called a real $n$-tuple.
Define $\Rinf$ to be the set of all real $n$-tuples for any $n$.
\begin{zed}
	\Rinf == \seq \R
\end{zed}

Define $\Rtuples(n)$ to be $\R^n$, the set of all $n$-tuples.
\begin{axdef}
	\Rtuples: \nat \fun \power \Rinf
\where
	\forall n: \nat @ \\
	\t1	\Rtuples(n) = \{~ v: \Rinf | \# v = n ~\}
\end{axdef}

The real numbers that comprise an $n$-tuple are called its components.
The real number $v(i)$ is the $i$-th component of the $n$-tuple $v$ where
$1 \le i \le n$.
Let $\pi(i)$ be the projection function that maps an $n$-tuple $v$ to its $i$-th component $v(i)$.

\begin{axdef}
	\pi: \nat_1 \fun \Rinf \pfun \R
\where
	\forall i: \nat_1 @ \\
	\t1	\pi(i) = (\lambda v: \Rinf | i \in \dom v @ v(i))
\end{axdef}

\subsection{Scalar Multiplication}

Let $v$ be an $n$-tuple and let $c$ be a real number.
Scalar multiplication of $v$ by $c$ is the $n$-tuple $c \smulR v$ defined by component-wise multiplication.

\begin{axdef}
	\_ \smulR \_ : \R \cross \Rinf \fun \Rinf 
\where
	\forall c: \R @ \\
	\t1	c \smulR \langle \rangle = \langle \rangle
\also
	\forall c: \R; n: \nat_1 @ \\
	\t1	\forall v: \Rtuples(n); i: 1 \upto n @ \\
	\t2		(c \smulR v)(i) = c \mulR v(i)
\end{axdef}

\subsection{Vector Addition and Subtraction}

Let $v$ and $w$ be $n$-tuples.
Vector addition of $v$ and $w$ is the $n$-tuple $v \vaddR w$ defined by component-wise addition.

\begin{axdef}
	\_ \vaddR \_: \Rinf \cross \Rinf \pfun \Rinf
\where
	\dom(\_ \vaddR \_) = \{~ v, w: \Rinf | \# v = \# w ~\}
\also
	\langle \rangle \vaddR \langle \rangle = \langle \rangle
\also
	\forall n: \nat_1 @ \\
	\t1	\forall v, w: \Rtuples(n); i: 1 \upto n @ \\
	\t2		(v \vaddR w)(i) = v(i) \addR w(i)
\end{axdef}

Vector subtraction is defined similarly.

\begin{axdef}
	\_ \vsubR \_: \Rinf \cross \Rinf \pfun \Rinf
\where
	\dom(\_ \vsubR \_) = \{~ v, w: \Rinf | \# v = \# w ~\}
\also
	\langle \rangle \vsubR \langle \rangle = \langle \rangle
\also
	\forall n: \nat_1 @ \\
	\t1	\forall v, w: \Rtuples(n); i: 1 \upto n @ \\
	\t2		(v \vsubR w)(i) = v(i) \subR w(i)
\end{axdef}

Each $\Rtuples(n)$ is a real vector space under the operations of scalar multiplication and vector addition
defined above. 

\subsection{Linear Transformations}

Let $n$ and $m$ be natural numbers.
A mapping $L$ from $\R^n$ to $\R^m$ is said to be a linear transformation if it preserves scalar multiplication and vector addition.
\begin{schema}{Linear}
	n, m: \nat \\
	L: \Rinf \pfun \Rinf
\where
	L \in \Rtuples(n) \fun \Rtuples(m)
\also
	\forall c: \R; v: \Rtuples(n) @ \\
	\t1	L(c \smulR v) = c \smulR L(v)
\also
	\forall v, w: \Rtuples(n) @ \\
	\t1	L(v \vaddR w) = L(v) \vaddR L(w)
\end{schema}

Define $\linR(n,m)$ to be the set of all linear transformations from $\R^n$ to $\R^m$.
\begin{axdef}
	\linR: \nat \cross \nat \fun \power(\Rinf \pfun \Rinf)
\where
	\forall n,m: \nat @ \\
	\t1	\linR(n,m) = \{~ L: \Rinf \pfun \Rinf | Linear ~\}
\end{axdef}

\subsection{The Dot Product}

The inner or dot product of $n$-tuples $v$ and $w$ is the real number $v \dotR w$ defined by the sum of the component-wise products.

\begin{axdef}
	\_ \dotR \_ : \Rinf \cross \Rinf \pfun \R
\where
	\dom(\_ \dotR \_) = \{~ v, w: \Rinf | \# v = \# w ~\}
\also
	\langle \rangle \dotR \langle \rangle = \zeroR
\also
	\forall x, y: \R; v, w: \Rinf | \# v = \# w @ \\
	\t1	(\langle x \rangle \cat v) \dotR (\langle y \rangle \cat w) = x \mulR y \addR v \dotR w
\end{axdef}

Each $\Rtuples(n)$ is a real inner product space under the operation of dot product defined above.

\subsection{The Norm}

The norm $\norm{v}$ of the $n$-tuple $v$ is the positive square root of its dot product with itself.
$$
	\norm{v} = \sqrt{v \dotR v}
$$

Define $\normR(v)$ to be $\norm{v}$.
\begin{axdef}
	\normR: \Rinf \fun \R
\where
	\forall v: \Rinf @ \\
	\t1	\normR(v) = \sqrtR(v \dotR v)
\end{axdef}

The concepts of continuity, limits, and differentiability extend to functions between normed vector spaces such as $\R^n$.

\subsection{Differentiability}

Let $f: \R^n \fun \R^m$ and let $x \in \R^n$.
Then $f$ is differentiable at $x$ if there exists a linear transformation $L: \R^n \fun \R^m$
such that $f$ is approximately linear very near $x$.
$$
f(x + h) \approx f(x) + L(h) \quad \text{when} \quad \norm{h} \approx 0
$$ 

\section{The 2-sphere as a Riemannian Manifold}

Consider the vector space of 3-tuples, $\Rthree$.
\begin{zed}
	\Rthree == \Rtuples(3)
\end{zed}

The 2-sphere, $\Stwo$ is the set of unit vectors in $\Rthree$.
$$
	\Stwo = \{~ v: \Rthree | \norm{v} = 1 ~\}
$$

\begin{axdef}
	\Stwo: \power \Rthree
\where
	\Stwo = \{~ v: \Rthree | \normR(v) = \oneR ~\}
\end{axdef}

\subsection{Coordinates on $\Rthree$}

Let $x, y, z$ be the usual Cartesian coordinate functions on $\Rthree$.
\begin{equation}
\forall p : \Rthree @ p = \langle x(p), y(p), z(p) \rangle
\end{equation}

Let $\langle e_1, e_2, e_3 \rangle$ be the usual orthonormal basis of $\Rthree$.
\begin{align}
e_1 & = \langle 1, 0, 0 \rangle \\
e_2 & = \langle 0, 1, 0 \rangle \\
e_3 & = \langle 0, 0, 1 \rangle
\end{align}

We have
\begin{equation}
\forall p : \Rthree @ p = x(p) e_1 + y(p) e_2 + z(p) e_3
\end{equation}

The Cartesian coordinate functions define the vector fields $\frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z}$
on $\Rthree$ as follows. 
For $p \in \Rthree$ and $f \in \smoothPR(\Rthree)$, we define
\begin{align}
\left(\frac{\partial}{\partial x}\right)_p f = \left. \frac{d}{dt} f(p + t e_1) \right|_{t = 0} \\
\left(\frac{\partial}{\partial y}\right)_p f = \left. \frac{d}{dt} f(p + t e_2) \right|_{t = 0} \\
\left(\frac{\partial}{\partial z}\right)_p f = \left. \frac{d}{dt} f(p + t e_3) \right|_{t = 0}
\end{align}

\printbibliography

\end{document}